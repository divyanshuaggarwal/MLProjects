{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C://Users//divya//Downloads//text-summarisation-pytorch\\news_summary.csv\nC://Users//divya//Downloads//text-summarisation-pytorch\\news_summary_more.csv\nC://Users//divya//Downloads//text-summarisation-pytorch\\text-summarization-in-pytorch.ipynb\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(\"C://Users//divya//Downloads//text-summarisation-pytorch\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'news_summary_more.csv'\n",
    "# glove_path = '/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.200d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headlines</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Delhi techie wins free food from Swiggy for on...</td>\n      <td>Kunal Shah's credit card bill payment platform...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n      <td>New Zealand defeated India by 8 wickets in the...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Aegon life iTerm insurance plan helps customer...</td>\n      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n      <td>Speaking about the sexual harassment allegatio...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data = pd.read_csv(data_path,encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " hi  . man tiger caller  walle\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower() # lowercase\n",
    "    text = text.split() # convert have'nt -> have not\n",
    "    for i in range(len(text)):\n",
    "        word = text[i]\n",
    "        if word in contraction_mapping:\n",
    "            text[i] = contraction_mapping[word]\n",
    "    text = \" \".join(text)\n",
    "    text = text.split()\n",
    "    newtext = []\n",
    "    for word in text:\n",
    "        if word not in stop_words:\n",
    "            newtext.append(word)\n",
    "    text = \" \".join(newtext)\n",
    "    text = text.replace(\"'s\",'') # convert your's -> your\n",
    "    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n",
    "    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n",
    "    text = re.sub(r'\\.',' . ',text)\n",
    "    return text\n",
    "\n",
    "sample = \"(hello) hi there .man tiger caller who's that isn't it ? WALL-E\"\n",
    "print(preprocess(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "think opposition even dreams me pm modi claiming dearth ideas among opposition parties prime minister narendra modi wednesday said the opposition talks modi whole day suspect even dream me .  pm modi addressing new india youth conclave in surat added opposition parties one agenda modi . \n"
     ]
    }
   ],
   "source": [
    "data['headlines'] = data['headlines'].apply(lambda x:preprocess(x))\n",
    "data['text'] = data['text'].apply(lambda x:preprocess(x))\n",
    "print(data['headlines'][20],data['text'][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "former finance minister yashwant sinha tuesday demanded probe alleged diversion loans worth 31000 crore dewan housing finance  .  agencies including regulators government failed track nefarious deals said .  comes media report tuesday accused dhfl controlling shareholders diverting funds shell companies buy assets . \nyashwant sinha demands probe alleged fund diversion dhfl\n"
     ]
    }
   ],
   "source": [
    "x = data['text']\n",
    "y = data['headlines']\n",
    "print(x[50],y[50],sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Torch Req**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(text, summary, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(summary)\n",
    "        output_lang = Lang(text)\n",
    "    else:\n",
    "        input_lang = Lang(text)\n",
    "        output_lang = Lang(summary)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading lines...\n",
      "Read 98401 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "0        saurav kant alumnus upgrad iiitb pg program ma...\n",
      "1        kunal shah credit card bill payment platform c...\n",
      "2        new zealand defeated india 8 wickets fourth od...\n",
      "3        aegon life iterm insurance plan customers enjo...\n",
      "4        speaking sexual harassment allegations rajkuma...\n",
      "                               ...                        \n",
      "98396    crpf jawan tuesday axed death sharpedged weapo...\n",
      "98397    uff yeh first song sonakshi sinha starrer upco...\n",
      "98398    according reports new version 1999 science fic...\n",
      "98399    new music video shows rapper snoop dogg aiming...\n",
      "98400    madhesi morcha alliance seven political partie...\n",
      "Name: text, Length: 98401, dtype: object 100293\n",
      "0        upgrad learner switches career ml  al 90 salar...\n",
      "1         delhi techie wins free food swiggy one year cred\n",
      "2        new zealand end rohit sharmaled india 12match ...\n",
      "3        aegon life iterm insurance plan helps customer...\n",
      "4                 known hirani yrs metoo claims true sonam\n",
      "                               ...                        \n",
      "98396           crpf jawan axed death maoists chhattisgarh\n",
      "98397        first song sonakshi sinha noor titled uff yeh\n",
      "98398                   the matrix film get reboot reports\n",
      "98399    snoop dogg aims gun clown dressed trump new video\n",
      "98400    madhesi morcha withdraws support nepalese gove...\n",
      "Name: headlines, Length: 98401, dtype: object 41363\n",
      "['indian cueist pankaj advani defeated amir sarkhosh iran win 18th international title form 15frame ibsf world snooker championship doha monday .  november 12 advani 17th world title venue ibsf world billiards championship defeating mike russell england . ', 'pankaj advani wins 18th intl title world snooker chip']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData( x, y , False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    print(\"Training....\")\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        if iter% 1000 == 0:\n",
    "            print(iter,\"/\",n_iters + 1)\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "1000 / 175001\n",
      "2000 / 175001\n",
      "3000 / 175001\n",
      "4000 / 175001\n",
      "5000 / 175001\n",
      "7m 30s (- 255m 13s) (5000 2%) 7.1030\n",
      "6000 / 175001\n",
      "7000 / 175001\n",
      "8000 / 175001\n",
      "9000 / 175001\n",
      "10000 / 175001\n",
      "14m 34s (- 240m 30s) (10000 5%) 7.0207\n",
      "11000 / 175001\n",
      "12000 / 175001\n",
      "13000 / 175001\n",
      "14000 / 175001\n",
      "15000 / 175001\n",
      "21m 35s (- 230m 23s) (15000 8%) 7.0548\n",
      "16000 / 175001\n",
      "17000 / 175001\n",
      "18000 / 175001\n",
      "19000 / 175001\n",
      "20000 / 175001\n",
      "28m 39s (- 222m 8s) (20000 11%) 7.0083\n",
      "21000 / 175001\n",
      "22000 / 175001\n",
      "23000 / 175001\n",
      "24000 / 175001\n",
      "25000 / 175001\n",
      "35m 40s (- 214m 2s) (25000 14%) 7.0136\n",
      "26000 / 175001\n",
      "27000 / 175001\n",
      "28000 / 175001\n",
      "29000 / 175001\n",
      "30000 / 175001\n",
      "42m 48s (- 206m 52s) (30000 17%) 6.9880\n",
      "31000 / 175001\n",
      "32000 / 175001\n",
      "33000 / 175001\n",
      "34000 / 175001\n",
      "35000 / 175001\n",
      "50m 0s (- 200m 0s) (35000 20%) 6.8620\n",
      "36000 / 175001\n",
      "37000 / 175001\n",
      "38000 / 175001\n",
      "39000 / 175001\n",
      "40000 / 175001\n",
      "57m 10s (- 192m 59s) (40000 22%) 6.7996\n",
      "41000 / 175001\n",
      "42000 / 175001\n",
      "43000 / 175001\n",
      "44000 / 175001\n",
      "45000 / 175001\n",
      "64m 20s (- 185m 52s) (45000 25%) 6.6842\n",
      "46000 / 175001\n",
      "47000 / 175001\n",
      "48000 / 175001\n",
      "49000 / 175001\n",
      "50000 / 175001\n",
      "71m 31s (- 178m 48s) (50000 28%) 6.6343\n",
      "51000 / 175001\n",
      "52000 / 175001\n",
      "53000 / 175001\n",
      "54000 / 175001\n",
      "55000 / 175001\n",
      "78m 44s (- 171m 47s) (55000 31%) 6.5368\n",
      "56000 / 175001\n",
      "57000 / 175001\n",
      "58000 / 175001\n",
      "59000 / 175001\n",
      "60000 / 175001\n",
      "85m 54s (- 164m 39s) (60000 34%) 6.4667\n",
      "61000 / 175001\n",
      "62000 / 175001\n",
      "63000 / 175001\n",
      "64000 / 175001\n",
      "65000 / 175001\n",
      "93m 3s (- 157m 28s) (65000 37%) 6.3805\n",
      "66000 / 175001\n",
      "67000 / 175001\n",
      "68000 / 175001\n",
      "69000 / 175001\n",
      "70000 / 175001\n",
      "100m 13s (- 150m 20s) (70000 40%) 6.2816\n",
      "71000 / 175001\n",
      "72000 / 175001\n",
      "73000 / 175001\n",
      "74000 / 175001\n",
      "75000 / 175001\n",
      "107m 21s (- 143m 8s) (75000 42%) 6.2486\n",
      "76000 / 175001\n",
      "77000 / 175001\n",
      "78000 / 175001\n",
      "79000 / 175001\n",
      "80000 / 175001\n",
      "114m 29s (- 135m 57s) (80000 45%) 6.1616\n",
      "81000 / 175001\n",
      "82000 / 175001\n",
      "83000 / 175001\n",
      "84000 / 175001\n",
      "85000 / 175001\n",
      "121m 39s (- 128m 49s) (85000 48%) 6.1359\n",
      "86000 / 175001\n",
      "87000 / 175001\n",
      "88000 / 175001\n",
      "89000 / 175001\n",
      "90000 / 175001\n",
      "128m 50s (- 121m 41s) (90000 51%) 6.0502\n",
      "91000 / 175001\n",
      "92000 / 175001\n",
      "93000 / 175001\n",
      "94000 / 175001\n",
      "95000 / 175001\n",
      "136m 3s (- 114m 34s) (95000 54%) 5.9712\n",
      "96000 / 175001\n",
      "97000 / 175001\n",
      "98000 / 175001\n",
      "99000 / 175001\n",
      "100000 / 175001\n",
      "143m 17s (- 107m 27s) (100000 57%) 5.9550\n",
      "101000 / 175001\n",
      "102000 / 175001\n",
      "103000 / 175001\n",
      "104000 / 175001\n",
      "105000 / 175001\n",
      "150m 32s (- 100m 21s) (105000 60%) 5.8733\n",
      "106000 / 175001\n",
      "107000 / 175001\n",
      "108000 / 175001\n",
      "109000 / 175001\n",
      "110000 / 175001\n",
      "157m 45s (- 93m 12s) (110000 62%) 5.8364\n",
      "111000 / 175001\n",
      "112000 / 175001\n",
      "113000 / 175001\n",
      "114000 / 175001\n",
      "115000 / 175001\n",
      "164m 55s (- 86m 3s) (115000 65%) 5.8099\n",
      "116000 / 175001\n",
      "117000 / 175001\n",
      "118000 / 175001\n",
      "119000 / 175001\n",
      "120000 / 175001\n",
      "172m 7s (- 78m 53s) (120000 68%) 5.7457\n",
      "121000 / 175001\n",
      "122000 / 175001\n",
      "123000 / 175001\n",
      "124000 / 175001\n",
      "125000 / 175001\n",
      "179m 21s (- 71m 44s) (125000 71%) 5.7293\n",
      "126000 / 175001\n",
      "127000 / 175001\n",
      "128000 / 175001\n",
      "129000 / 175001\n",
      "130000 / 175001\n",
      "186m 38s (- 64m 36s) (130000 74%) 5.6507\n",
      "131000 / 175001\n",
      "132000 / 175001\n",
      "133000 / 175001\n",
      "134000 / 175001\n",
      "135000 / 175001\n",
      "193m 54s (- 57m 27s) (135000 77%) 5.6422\n",
      "136000 / 175001\n",
      "137000 / 175001\n",
      "138000 / 175001\n",
      "139000 / 175001\n",
      "140000 / 175001\n",
      "201m 11s (- 50m 17s) (140000 80%) 5.5948\n",
      "141000 / 175001\n",
      "142000 / 175001\n",
      "143000 / 175001\n",
      "144000 / 175001\n",
      "145000 / 175001\n",
      "208m 24s (- 43m 7s) (145000 82%) 5.5903\n",
      "146000 / 175001\n",
      "147000 / 175001\n",
      "148000 / 175001\n",
      "149000 / 175001\n",
      "150000 / 175001\n",
      "215m 34s (- 35m 55s) (150000 85%) 5.5016\n",
      "151000 / 175001\n",
      "152000 / 175001\n",
      "153000 / 175001\n",
      "154000 / 175001\n",
      "155000 / 175001\n",
      "222m 43s (- 28m 44s) (155000 88%) 5.4789\n",
      "156000 / 175001\n",
      "157000 / 175001\n",
      "158000 / 175001\n",
      "159000 / 175001\n",
      "160000 / 175001\n",
      "229m 52s (- 21m 33s) (160000 91%) 5.4780\n",
      "161000 / 175001\n",
      "162000 / 175001\n",
      "163000 / 175001\n",
      "164000 / 175001\n",
      "165000 / 175001\n",
      "237m 4s (- 14m 22s) (165000 94%) 5.4187\n",
      "166000 / 175001\n",
      "167000 / 175001\n",
      "168000 / 175001\n",
      "169000 / 175001\n",
      "170000 / 175001\n",
      "244m 14s (- 7m 11s) (170000 97%) 5.4261\n",
      "171000 / 175001\n",
      "172000 / 175001\n",
      "173000 / 175001\n",
      "174000 / 175001\n",
      "175000 / 175001\n",
      "251m 25s (- 0m 0s) (175000 100%) 5.3640\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 300\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 175000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder1.state_dict(), './enc.w')\n",
    "torch.save(attn_decoder1.state_dict(), './att.w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> police constable javaid ahmad dar kidnapped terrorists local medical shop jammu kashmir shopian thursday found dead friday kulgam .  reportedly picture dar shirtless suspected taken abductors also surfaced online .  last month army jawan aurangzeb abducted killed terrorists . \n",
      "= policeman kidnapped terrorists found dead jk\n",
      "< jk cop cop killed encounter kashmir kashmir <EOS>\n",
      "\n",
      "> astronomers discovered rare binary system consisting body failed generate enough fusion become star called brown dwarf dead fuelexhausted stellar remnant white dwarf .  scientists found orbit 100 kmsec completing orbit 71 minutes white dwarf would cannibalise brown dwarf future . \n",
      "= newfound failed star orbits dead star every 71 mins\n",
      "< nasa found dead using using using <EOS>\n",
      "\n",
      "> accusing washington post new york times peddling fake news us president donald trump slammed newspapers saying theyll business seven years .  twitter getting rid fake accounts record pace .  include failing new york times washington post constantly quote anonymous sources added . \n",
      "= business trump slams washington post nyt\n",
      "< trump tweets us fake news <EOS>\n",
      "\n",
      "> former australian spinner shane warne said punishment meted david warner steve smith form oneyear ban balltampering does fit crime .  my punishment would miss fourth test .  .  . a huge fine sacked captain vicecaptain said .  warne also added cheating unaustralian . \n",
      "= punishment fit crime warne smith warner ban\n",
      "< smith smith warner smith smith smith smith smith <EOS>\n",
      "\n",
      "> taking dig congress president rahul gandhi ahead noconfidence motion debate bjp mp paresh rawal said if rahul speak 15 minutes without reading paper without .  .  . mistakes mother earth shake .  itll shake dance added .  may pm narendra modi challenged rahul speak 15 minutes without paper . \n",
      "= earth shake rahul speaks without mistakes bjp mp paresh\n",
      "< rahul gandhi without without without rahul <EOS>\n",
      "\n",
      "> pehlu khan  assaulted around 15 people alwar highway suspicion cow smuggling rajasthan died hospital monday said police .  khan among people transporting cows six vehicles .  we registered case murder six persons 200 unknown people said sho bahror alwar . \n",
      "= man attacked cow vigilantes rajasthan dies\n",
      "< cow cow cow cow cow cow death <EOS>\n",
      "\n",
      "> district administration bulandshahr invoked national security act  three men accused alleged cow slaughter led mob violence december policeman youth killed .  district magistrate anuj jha said nsa invoked keeping mind chance three accused might get bail . \n",
      "= national security act invoked bulandshahr violence case\n",
      "< death penalty death penalty mob death penalty <EOS>\n",
      "\n",
      "> around nine deliveries performed candlelight torchlight governmentrun dehradun hospital electricity disrupted several hours .  hospital said power supply could resumed due glitch generator electrician employed leave .  power reportedly disrupted tuesday resumed 14 hours wednesday . \n",
      "= 9 babies delivered candlelight electrician goes leave\n",
      "< study hospital hospital hospital hospital <EOS>\n",
      "\n",
      "> cristiano ronaldo reportedly get paid 30 million annually new club juventus four times salary italian club highest earner exreal madrid teammate gonzalo higuan .  further based italy taxation rates ronaldo gross pay including bonuses would lesser real madrid pay four champions league nine years . \n",
      "= ronaldo pay new club 4 times top earner\n",
      "< ronaldo buys 4 cr 4 cr <EOS>\n",
      "\n",
      "> actor sumeet raghavan portrayed character dr sahil sarabhai show arabhai vs sarabhai said rewatching show order prepare upcoming web series .  there change far look concerned added .  sumeet said cannot wait start shooting web series . \n",
      "= rewatching sarabhai vs sarabhai web series sumeet\n",
      "< cannot show show show michael <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}