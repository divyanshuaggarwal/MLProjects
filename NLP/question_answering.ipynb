{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "22046137496f44b4a3f12fb706962bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_454595804b1f4b4690b25966de2cc29a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a25faaa306a549a995af8193cd3dfe65",
              "IPY_MODEL_08aeffd812664c74b404abfe48af3541"
            ]
          }
        },
        "454595804b1f4b4690b25966de2cc29a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a25faaa306a549a995af8193cd3dfe65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4111337f67844d96bc4991200b1ae701",
            "_dom_classes": [],
            "description": "Finding best initial lr: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26824824e44f4720a74ca014a7e613f8"
          }
        },
        "08aeffd812664c74b404abfe48af3541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d730886d8d9d4ac89f478944cf354fbe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [01:29&lt;00:00,  1.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7c39e027e024acfa9528373718464d0"
          }
        },
        "4111337f67844d96bc4991200b1ae701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26824824e44f4720a74ca014a7e613f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d730886d8d9d4ac89f478944cf354fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7c39e027e024acfa9528373718464d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce852f7759aa4ef5a272491729fbf77c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea0370268c4a4e00b9f3f7ebfc4b9dfc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ddb9c5380ec4d4ab80a9c5792bdb48e",
              "IPY_MODEL_910b488b64d74adfbf0d08b0242d47d8"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op-7d7L60mHY"
      },
      "source": [
        "# Installing Libraries and Downloading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI5hmejdXROw"
      },
      "source": [
        "! pip install -q datasets transformers tokenizers\r\n",
        "from datasets import load_dataset, load_metric"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq5ud3EvXnge",
        "outputId": "c67d5356-ae8e-4f33-a8d1-a6fab3430039"
      },
      "source": [
        "!mkdir squad\r\n",
        "\r\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squad/train-v2.0.json\r\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O squad/dev-v2.0.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory â€˜squadâ€™: File exists\n",
            "--2020-12-23 18:09:21--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: â€˜squad/train-v2.0.jsonâ€™\n",
            "\n",
            "squad/train-v2.0.js 100%[===================>]  40.17M   243MB/s    in 0.2s    \n",
            "\n",
            "2020-12-23 18:09:21 (243 MB/s) - â€˜squad/train-v2.0.jsonâ€™ saved [42123633/42123633]\n",
            "\n",
            "--2020-12-23 18:09:21--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: â€˜squad/dev-v2.0.jsonâ€™\n",
            "\n",
            "squad/dev-v2.0.json 100%[===================>]   4.17M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-12-23 18:09:22 (75.6 MB/s) - â€˜squad/dev-v2.0.jsonâ€™ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSfq20gt03S_"
      },
      "source": [
        "# Reading the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tZvHmSnXnvt"
      },
      "source": [
        "import json\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "def read_squad(path):\r\n",
        "    path = Path(path)\r\n",
        "    with open(path, 'rb') as f:\r\n",
        "        squad_dict = json.load(f)\r\n",
        "\r\n",
        "    contexts = []\r\n",
        "    questions = []\r\n",
        "    answers = []\r\n",
        "    for group in squad_dict['data']:\r\n",
        "        for passage in group['paragraphs']:\r\n",
        "            context = passage['context']\r\n",
        "            for qa in passage['qas']:\r\n",
        "                question = qa['question']\r\n",
        "                for answer in qa['answers']:\r\n",
        "                    contexts.append(context)\r\n",
        "                    questions.append(question)\r\n",
        "                    answers.append(answer)\r\n",
        "\r\n",
        "    return contexts, questions, answers\r\n",
        "\r\n",
        "train_contexts, train_questions, train_answers = read_squad('squad/train-v2.0.json')\r\n",
        "val_contexts, val_questions, val_answers = read_squad('squad/dev-v2.0.json')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c94HGD0E05c6"
      },
      "source": [
        "# preprocessing the data for QA format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRe-JL0iZeVv"
      },
      "source": [
        "def add_end_idx(answers, contexts):\r\n",
        "    for answer, context in zip(answers, contexts):\r\n",
        "        gold_text = answer['text']\r\n",
        "        start_idx = answer['answer_start']\r\n",
        "        end_idx = start_idx + len(gold_text)\r\n",
        "\r\n",
        "        # sometimes squad answers are off by a character or two â€“ fix this\r\n",
        "        if context[start_idx:end_idx] == gold_text:\r\n",
        "            answer['answer_end'] = end_idx\r\n",
        "        elif context[start_idx-1:end_idx-1] == gold_text:\r\n",
        "            answer['answer_start'] = start_idx - 1\r\n",
        "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\r\n",
        "        elif context[start_idx-2:end_idx-2] == gold_text:\r\n",
        "            answer['answer_start'] = start_idx - 2\r\n",
        "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\r\n",
        "\r\n",
        "add_end_idx(train_answers, train_contexts)\r\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLWyBJZn09Ir"
      },
      "source": [
        "## Tokenising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVt-x52RZg0P"
      },
      "source": [
        "from transformers import DistilBertTokenizerFast\r\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\r\n",
        "\r\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\r\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V6tPZRZ1APT"
      },
      "source": [
        "## Adding Token Position"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG1BDX9fZim9"
      },
      "source": [
        "def add_token_positions(encodings, answers):\r\n",
        "    start_positions = []\r\n",
        "    end_positions = []\r\n",
        "    for i in range(len(answers)):\r\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\r\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\r\n",
        "        # if None, the answer passage has been truncated\r\n",
        "        if start_positions[-1] is None:\r\n",
        "            start_positions[-1] = tokenizer.model_max_length\r\n",
        "        if end_positions[-1] is None:\r\n",
        "            end_positions[-1] = tokenizer.model_max_length\r\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\r\n",
        "\r\n",
        "add_token_positions(train_encodings, train_answers)\r\n",
        "add_token_positions(val_encodings, val_answers)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw9ZmBxb1DlT"
      },
      "source": [
        "## Converting the tokens to pytorch data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ov_ojGGZkYW"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "class SquadDataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, encodings):\r\n",
        "        self.encodings = encodings\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.encodings.input_ids)\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxFiW0hjZwtl"
      },
      "source": [
        "!pip install -q pytorch_lightning\r\n",
        "\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from transformers import AdamW\r\n",
        "import pytorch_lightning as pl\r\n",
        "from transformers import DistilBertForQuestionAnswering"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDAo6oJK1IZC"
      },
      "source": [
        "# Defining the Model in Pytorch Lightning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPpAhDp_t-6X"
      },
      "source": [
        "class QA_BERT(pl.LightningModule):\r\n",
        "  def __init__(self,lr=0.0005):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\r\n",
        "\r\n",
        "    self.lr= lr\r\n",
        "\r\n",
        "  def forward(self,input_ids,attention_mask,start_positions,end_positions):\r\n",
        "\r\n",
        "    return self.model(input_ids,\r\n",
        "                      attention_mask=attention_mask,\r\n",
        "                      start_positions=start_positions, \r\n",
        "                      end_positions=end_positions\r\n",
        "                      )\r\n",
        "\r\n",
        "  def training_step(self, batch, batch_idx):\r\n",
        "    input_ids = batch['input_ids'].to(self.device)\r\n",
        "    attention_mask = batch['attention_mask'].to(self.device)\r\n",
        "    start_positions = batch['start_positions'].to(self.device)\r\n",
        "    end_positions = batch['end_positions'].to(self.device)\r\n",
        "    outputs = self(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\r\n",
        "    loss = outputs[0]\r\n",
        "    return loss\r\n",
        "\r\n",
        "  def validation_step(self,batch,batch_idx):\r\n",
        "    input_ids = batch['input_ids'].to(self.device)\r\n",
        "    attention_mask = batch['attention_mask'].to(self.device)\r\n",
        "    start_positions = batch['start_positions'].to(self.device)\r\n",
        "    end_positions = batch['end_positions'].to(self.device)\r\n",
        "    outputs = self(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\r\n",
        "    loss = outputs[0]\r\n",
        "    return loss\r\n",
        "\r\n",
        "  def configure_optimizers(self):\r\n",
        "    return AdamW(self.parameters(), lr=self.lr)\r\n",
        "\r\n",
        "  def prepare_data(self,stage=None):\r\n",
        "    self.train_dataset = SquadDataset(train_encodings)\r\n",
        "    self.val_dataset = SquadDataset(val_encodings)\r\n",
        "\r\n",
        "  def setup(self,stage=None):\r\n",
        "\r\n",
        "    self.train_loader = DataLoader(self.train_dataset,\r\n",
        "                              batch_size=16,\r\n",
        "                              shuffle= True,\r\n",
        "                              )\r\n",
        "\r\n",
        "    self.val_loader = DataLoader(self.val_dataset, \r\n",
        "                            batch_size=16,\r\n",
        "                            shuffle =False,\r\n",
        "                            )\r\n",
        "\r\n",
        "  def train_dataloader(self):\r\n",
        "    return self.train_loader\r\n",
        "\r\n",
        "  def val_dataloader(self):\r\n",
        "    return self.val_loader"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmVQp7K_1OH_"
      },
      "source": [
        "# Initialising the Model and Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "22046137496f44b4a3f12fb706962bca",
            "454595804b1f4b4690b25966de2cc29a",
            "a25faaa306a549a995af8193cd3dfe65",
            "08aeffd812664c74b404abfe48af3541",
            "4111337f67844d96bc4991200b1ae701",
            "26824824e44f4720a74ca014a7e613f8",
            "d730886d8d9d4ac89f478944cf354fbe",
            "b7c39e027e024acfa9528373718464d0"
          ]
        },
        "id": "xq1J9iqgbunL",
        "outputId": "9420a039-ad8e-490d-d394-6af24131ae0a"
      },
      "source": [
        "from pytorch_lightning import Trainer\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "trainer = Trainer(max_epochs=1,\r\n",
        "                  fast_dev_run=False,\r\n",
        "                  gpus=(-1 if torch.cuda.is_available() else 0),\r\n",
        "                  auto_lr_find=True,\r\n",
        "                  )\r\n",
        "\r\n",
        "model = QA_BERT()\r\n",
        "\r\n",
        "trainer.tune(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\n",
            "  | Name  | Type                           | Params\n",
            "---------------------------------------------------------\n",
            "0 | model | DistilBertForQuestionAnswering | 66.4 M\n",
            "---------------------------------------------------------\n",
            "66.4 M    Trainable params\n",
            "0         Non-trainable params\n",
            "66.4 M    Total params\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22046137496f44b4a3f12fb706962bca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.0002089296130854041\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwIDUO6ScoLH",
        "outputId": "ae1a6a18-0951-4b3c-ddbb-5188d09ba1c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "ce852f7759aa4ef5a272491729fbf77c"
          ]
        }
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name  | Type                           | Params\n",
            "---------------------------------------------------------\n",
            "0 | model | DistilBertForQuestionAnswering | 66.4 M\n",
            "---------------------------------------------------------\n",
            "66.4 M    Trainable params\n",
            "0         Non-trainable params\n",
            "66.4 M    Total params\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce852f7759aa4ef5a272491729fbf77c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layoutâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0c1ef3c9bfa4084957b925702f4334d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiQUuUQaxiqz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}