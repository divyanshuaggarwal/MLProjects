{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58a78aa9939abef7ee8cbf2e02ab525beede0585"
   },
   "source": [
    "# Urban Sound Classification\n",
    "8732 labeled sound excerpts of urban sounds from 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96943013e215fb407a349d69e940fc1e7dff3578"
   },
   "source": [
    "## <b>Context</b>\n",
    "    \n",
    "The automatic classification of environmental sound is a growing research field with multiple applications to largescale, content-based multimedia indexing and retrieval. In particular, the sonic analysis of urban environments is the subject of increased interest, partly enabled by multimedia sensor networks, as well as by large quantities of online multimedia content depicting urban scenes.\n",
    "\n",
    "However, while there is a large body of research in related areas such as speech, music and bioacoustics, work on the analysis of urban acoustic environments is relatively scarce.Furthermore, when existent, it mostly focuses on the classification of auditory scene type, e.g. street, park, as opposed to the identification of sound sources in those scenes, e.g.car horn, engine idling, bird tweet.\n",
    "\n",
    "There are primarily two major challenges with urban sound research namely\n",
    "\n",
    "<ul><li>Lack of labeled audio data. Previous work has focused on audio from carefully produced movies or television tracks from specific environments such as elevators or office spaces and on commercial or proprietary datasets . The large effort involved in manually annotating real-world data means datasets based on field recordings tend to be relatively small (e.g. the event detection dataset of the IEEE AASP Challenge consists of 24 recordings per each of 17 classes).</li></ul>\n",
    "<ul><li>Lack of common vocabulary when working on urban sounds.This means the classification of sounds into semantic groups may vary from study to study, making it hard to compare results so the objective of this notebook is to address the above two mentioned challenges.</li></ul>\n",
    "\n",
    "## <b>Content</b>\n",
    "The dataset is called UrbanSound and contains 8732 labeled sound excerpts (<=4s) of urban sounds from 10 classes: - The dataset contains 8732 sound excerpts (<=4s) of urban sounds from 10 classes, namely: Air Conditioner Car Horn Children Playing Dog bark Drilling Engine Idling Gun Shot Jackhammer Siren Street Music The attributes of data are as follows: ID – Unique ID of sound excerpt Class – type of sound\n",
    "\n",
    "## <b>Acknowledgements</b>\n",
    "Source of the dataset : https://drive.google.com/drive/folders/0By0bAi7hOBAFUHVXd1JCN3MwTEU\n",
    "\n",
    "Source of research document : https://serv.cusp.nyu.edu/projects/urbansounddataset/salamon_urbansound_acmmm14.pdf\n",
    "\n",
    "Source of Technique used : [CNN ARCHITECTURES FOR LARGE-SCALE AUDIO CLASSIFICATION](https://arxiv.org/pdf/1609.09430.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85f843b212ebbc7e7bbcc4e3fa406443c68cedd3"
   },
   "source": [
    "## Importing Basic Libraries and Installing Tools Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from memory_profiler import memory_usage\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09271a053e281dfc16252926dd1bad77ce7bbbc0"
   },
   "source": [
    "\n",
    "### Installing libav-tools to get Librosa Working Properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "e65b0eb0077460f117a3148493ad887ac7e6037e"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt-get install libav-tools -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3daa5ab32c049dce1fec83d8c180d62b7f523a2f"
   },
   "source": [
    "### Importing Fast.ai for Deep Learning and Librosa for Creating Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b7f4ca234dc0f182b0738eda27f7a8d913624779"
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import matplotlib\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6a4d7f4b7e3ebbb578f380be6ef9e8a601f2d629"
   },
   "source": [
    "### Making Temporary Working Directories for Storing the Audio Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "5ed95c35fb1ba38f4b5ed5d5631d14339bc7a813",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/train\n",
    "!mkdir /kaggle/working/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3b5f32ecf6ba74a889e271a974a6e5f372871e8"
   },
   "source": [
    "## Defining the Create Spectrogram Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "95e214ba7b173fd9e5d8b0f4f8d69e09ad657630"
   },
   "outputs": [],
   "source": [
    "def create_spectrogram(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = Path('/kaggle/working/train/' + name + '.jpg')\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b58e9171499d4b39992318a0a039e617626e9d2a"
   },
   "outputs": [],
   "source": [
    "def create_spectrogram_test(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = Path('/kaggle/working/test/' + name + '.jpg')\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9ce2e26375972e09b895aad8cd2ae146470a23e"
   },
   "source": [
    "### Splitting the Conversion in different cells and collecting the garbage to avoid Ram Overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c6099dc3c5fc83b4108bf4e1fe7f84ef3c923779"
   },
   "outputs": [],
   "source": [
    "Data_dir=np.array(glob(\"../input/train/Train/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "03413a7044c5428c3e882a449eff2aa47851b181"
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7159f9cebe7d3b61baf3bf155610055d67e214d4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 409.26 MiB, increment: 36.33 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "i=0\n",
    "for file in Data_dir[i:i+1500]:\n",
    "    filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "    create_spectrogram(filename,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "b784ca29e912ef683e05bd99040ffed9f99b94f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25196"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "3e5503be15c42d8f989346789df267331184994b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 409.65 MiB, increment: 11.08 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "i=1500\n",
    "for file in Data_dir[i:i+1500]:\n",
    "    filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "    create_spectrogram(filename,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "61ddd53c496bb225caeea1ee3fc56bd6a438ea4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23794"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "c4d5b9f808e4b9ce93c76e3ebd2f41684cd52507",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 409.80 MiB, increment: 14.37 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "i=3000\n",
    "for file in Data_dir[i:i+1500]:\n",
    "    filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "    create_spectrogram(filename,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "0c42a93f7f14d8ff04090cddec3e5f7c6864a7f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23798"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "fbbd2e78bd69f5c655f13d999b34c290ac42ed20",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 409.70 MiB, increment: 10.61 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "i=4500\n",
    "for file in Data_dir[i:]:\n",
    "    filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "    create_spectrogram(filename,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "3cf0b7703f75279d9b436c440a7db61887366a1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11249"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63b48f95754e02b69978cd19151edaafc90d03f5"
   },
   "source": [
    "## Creating Data Bunch for Training and Creating a Resnet34 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "11e7773bb54aa2515a71519153286b544a4c7e97"
   },
   "outputs": [],
   "source": [
    "path = Path('/kaggle/working/')\n",
    "np.random.seed(42)\n",
    "data = ImageDataBunch.from_csv(path,csv_labels='../input/train.csv', folder=\"train\", valid_pct=0.2, suffix='.jpg',\n",
    "        ds_tfms=get_transforms(), size=224, num_workers=0).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "478304196c9f307029f1863b299ac939e47ea445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_conditioner',\n",
       " 'car_horn',\n",
       " 'children_playing',\n",
       " 'dog_bark',\n",
       " 'drilling',\n",
       " 'engine_idling',\n",
       " 'gun_shot',\n",
       " 'jackhammer',\n",
       " 'siren',\n",
       " 'street_music']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "aaba3bf78e567a70fdc6be55f590b43908cc8101"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /tmp/.torch/models/resnet34-333f7ec4.pth\n",
      "100%|██████████| 87306240/87306240 [00:01<00:00, 83971372.66it/s]\n"
     ]
    }
   ],
   "source": [
    "learn = create_cnn(data, models.resnet34, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8938e47527547c64f1ead14506a2ebef75432cc"
   },
   "source": [
    "## Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "514f0287b57f373daca6d9cfa378063902afb198"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 05:20 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.718776</th>\n",
       "    <th>0.926031</th>\n",
       "    <th>0.673413</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.136074</th>\n",
       "    <th>0.755203</th>\n",
       "    <th>0.726771</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.870916</th>\n",
       "    <th>0.600213</th>\n",
       "    <th>0.794848</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.746269</th>\n",
       "    <th>0.567910</th>\n",
       "    <th>0.816007</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "ceed93c068f063d493d9e8f215ad79c4c56d5faa"
   },
   "outputs": [],
   "source": [
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "5864e90df6e03f75e352e07f54060fc39ecaebd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "d3d162626df53b0415fde28fdceb3e687f0fb8ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 06:13 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.561160</th>\n",
       "    <th>0.738423</th>\n",
       "    <th>0.791168</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.418634</th>\n",
       "    <th>0.301567</th>\n",
       "    <th>0.903404</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.245435</th>\n",
       "    <th>0.144982</th>\n",
       "    <th>0.959522</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.140169</th>\n",
       "    <th>0.134092</th>\n",
       "    <th>0.958602</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, max_lr=slice(1e-4,1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "3913c55bd52ffe17ce9fa4520c4e5c0052696dc0"
   },
   "outputs": [],
   "source": [
    "learn.save('stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "9efd56784c3a58be9b05a9c02996fadb747291d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "faeafc7dee56ed2e12b4105907ee4bc994ee6123"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:32 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.082762</th>\n",
       "    <th>0.129010</th>\n",
       "    <th>0.962282</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, max_lr=slice(1e-6,2e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "87d089f723dc5a2e4d5e9f76146e3d3f3f96d9a6"
   },
   "outputs": [],
   "source": [
    "learn.save('stage-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "f1a7b41b52874b12962a6e95dede0c5f1a7ecbb0"
   },
   "outputs": [],
   "source": [
    "Test_dir=np.array(glob(\"../input/test/Test/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "5d6dc7004c1f41552bbac9d70b985c8abe11d8ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1988.93 MiB, increment: 14.61 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "i=0\n",
    "for file in Test_dir[i:i+1500]:\n",
    "    filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "    create_spectrogram_test(filename,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "6d8439b0b8439235b96e23ecd8cb7a7fbadd1c9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22397"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "b30170499762fac307908b7ede5fb4852ead9747"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n",
      "/opt/conda/lib/python3.6/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1988.95 MiB, increment: 1.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "i=1500\n",
    "for file in Test_dir[i:]:\n",
    "    filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "    create_spectrogram_test(filename,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "9f079adcbab1c59918fbdafcd79c659ce2495fbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14052"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "88d4732aff727a6de7becf8d0bf77a0ef599c0df"
   },
   "outputs": [],
   "source": [
    "learn.load('stage-3')\n",
    "test_csv = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b905aca0bb936d12d00c052e754eadffc530247"
   },
   "source": [
    "## Making predictions and writing it to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "b48007cb1c20925e724b435c213ae72ff88030b3"
   },
   "outputs": [],
   "source": [
    "with open('output.csv',\"w\") as file:\n",
    "    file.write(\"ID,Prediction\\n\")\n",
    "    for test in test_csv.ID:\n",
    "        img = open_image('/kaggle/working/test/'+str(test)+'.jpg')\n",
    "        prediction = str(learn.predict(img)[0]).split()[0]\n",
    "        file.write(str(test)+','+prediction)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "f8fadc76b9c8a1b2f5630a6d82911dd41ed231db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>jackhammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID        Prediction\n",
       "0   5        jackhammer\n",
       "1   7  children_playing\n",
       "2   8          drilling\n",
       "3   9          dog_bark\n",
       "4  13      street_music"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.read_csv('output.csv')\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39e6dd92fd3a692c621217eeb106068122c02d41"
   },
   "source": [
    "### Removing Unwanted Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "c6b94bb83c3022b7d222b8b6b3f73cc989839ab9"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt-get install zip\n",
    "!zip -r train.zip /kaggle/working/train/\n",
    "!zip -r test.zip /kaggle/working/test/\n",
    "!rm -rf train/*\n",
    "!rm -rf test/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
