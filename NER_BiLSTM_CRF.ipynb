{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_BiLSTM_CRF.ipynb",
      "provenance": [],
      "mount_file_id": "1F2datjS7xGr8DbOYKmvF9rmt48v4_N4o",
      "authorship_tag": "ABX9TyNEq2KhamZ+3lkHByAU3+N+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyanshuaggarwal/MyProjects/blob/master/NER_BiLSTM_CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNttWej9Rqli",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition\n",
        "\n",
        "[dataset](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus#ner_dataset.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z4-94yoBJ_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = \"/content/drive/My Drive/ner_dataset.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI287Ly4Rn2T",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-ZGb6FCOvOV",
        "colab_type": "code",
        "outputId": "759b1aa1-c387-4f05-cc29-338613875b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import LSTM, Dense, TimeDistributed, Embedding, Bidirectional\n",
        "from keras.models import Model, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "!pip install seqeval\n",
        "!pip install sklearn_crfsuite\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-g2hw42sy\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-g2hw42sy\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=6fc4c15e7c77904f34827418e69116d7957186938b59fe9c84a0b7156d925f92\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_fefc8k9/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.2)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.38.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJGH_mItOxv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Reading the csv file\n",
        "df = pd.read_csv(file_path, encoding = \"ISO-8859-1\", error_bad_lines=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcVvT03bPhN_",
        "colab_type": "code",
        "outputId": "92c10061-ff74-4b44-cb55-bc55fd3db4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS    Tag\n",
              "0  Sentence: 1      Thousands  NNS      O\n",
              "1          NaN             of   IN      O\n",
              "2          NaN  demonstrators  NNS      O\n",
              "3          NaN           have  VBP      O\n",
              "4          NaN        marched  VBN      O\n",
              "5          NaN        through   IN      O\n",
              "6          NaN         London  NNP  B-geo\n",
              "7          NaN             to   TO      O\n",
              "8          NaN        protest   VB      O\n",
              "9          NaN            the   DT      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_RDEwhcPyWl",
        "colab_type": "code",
        "outputId": "f3d07973-e0ee-45c6-e1ee-e78dab761939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "df.describe()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>47959</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>47959</td>\n",
              "      <td>35178</td>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Sentence: 765</td>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>52573</td>\n",
              "      <td>145807</td>\n",
              "      <td>887908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Sentence #     Word      POS      Tag\n",
              "count           47959  1048575  1048575  1048575\n",
              "unique          47959    35178       42       17\n",
              "top     Sentence: 765      the       NN        O\n",
              "freq                1    52573   145807   887908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ7BP9gkP0ik",
        "colab_type": "code",
        "outputId": "aae4c72c-a117-4f1a-8b0e-e8d60dabb319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Displaying the unique Tags\n",
        "df['Tag'].unique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
              "       'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jDHV2vcP2Xl",
        "colab_type": "code",
        "outputId": "25a94924-23be-4df1-939a-8f10a6519847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Checking null values, if any.\n",
        "df.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    1000616\n",
              "Word                0\n",
              "POS                 0\n",
              "Tag                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hiv4jHRyQDlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.fillna(method = 'ffill')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ23_UC2QFWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class sentence(object):\n",
        "    def __init__(self, df):\n",
        "        self.n_sent = 1\n",
        "        self.df = df\n",
        "        self.empty = False\n",
        "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
        "                                                       s['POS'].values.tolist(),\n",
        "                                                       s['Tag'].values.tolist())]\n",
        "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "        \n",
        "    def get_text(self):\n",
        "        try:\n",
        "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
        "            self.n_sent +=1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CveV-oQHQHMd",
        "colab_type": "code",
        "outputId": "3c675ad5-c9b2-4280-a7dc-f2e8f9665454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Displaying one full sentence\n",
        "getter = sentence(df)\n",
        "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
        "sentences[0]\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9bn-cfDQJIw",
        "colab_type": "code",
        "outputId": "4845b56f-1f4d-4d3d-c992-e88c7f02a692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#sentence with its pos and tag.\n",
        "sent = getter.get_text()\n",
        "print(sent)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bYMhyMZRfIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = getter.sentences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkVws4jaRltr",
        "colab_type": "text"
      },
      "source": [
        "## Defining the parameters for LSTM network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxD89YHGRifV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of data points passed in each iteration\n",
        "batch_size = 64 \n",
        "# Passes through entire dataset\n",
        "epochs = 8\n",
        "# Maximum length of review\n",
        "max_len = 75 \n",
        "# Dimension of embedding vector\n",
        "embedding = 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eM7vTb5R1QU",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3gFqhtHR0gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting unique words and labels from data\n",
        "words = list(df['Word'].unique())\n",
        "tags = list(df['Tag'].unique())\n",
        "# Dictionary word:index pair\n",
        "# word is key and its value is corresponding index\n",
        "word_to_index = {w : i + 2 for i, w in enumerate(words)}\n",
        "word_to_index[\"UNK\"] = 1\n",
        "word_to_index[\"PAD\"] = 0\n",
        "\n",
        "# Dictionary lable:index pair\n",
        "# label is key and value is index.\n",
        "tag_to_index = {t : i + 1 for i, t in enumerate(tags)}\n",
        "tag_to_index[\"PAD\"] = 0\n",
        "\n",
        "idx2word = {i: w for w, i in word_to_index.items()}\n",
        "idx2tag = {i: w for w, i in tag_to_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckuo6CB_R8ZM",
        "colab_type": "code",
        "outputId": "38fe853c-41f3-4e86-f1ca-93963d694b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"The word India is identified by the index: {}\".format(word_to_index[\"India\"]))\n",
        "print(\"The label B-org for the organization is identified by the index: {}\".format(tag_to_index[\"B-org\"]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The word India is identified by the index: 2570\n",
            "The label B-org for the organization is identified by the index: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LuATAYJR-SW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [[word_to_index[w[0]] for w in s] for s in sentences]\n",
        "\n",
        "# Padding each sequence to have same length  of each word\n",
        "X = pad_sequences(maxlen = max_len, sequences = X, padding = \"post\", value = word_to_index[\"PAD\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR_mGU3_SArC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = [[tag_to_index[w[2]] for w in s] for s in sentences]\n",
        "\n",
        "# padding\n",
        "y = pad_sequences(maxlen = max_len, sequences = y, padding = \"post\", value = tag_to_index[\"PAD\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAGFCaQzSCMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tag = df['Tag'].nunique()\n",
        "# One hot encoded labels\n",
        "y = [to_categorical(i, num_classes = num_tag + 1) for i in y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_DV9gE9SDfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9zensPtSEmv",
        "colab_type": "code",
        "outputId": "f819497d-fe06-4e53-c90c-6d3c5b1127b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Size of training input data : \", X_train.shape)\n",
        "print(\"Size of training output data : \", np.array(y_train).shape)\n",
        "print(\"Size of testing input data : \", X_test.shape)\n",
        "print(\"Size of testing output data : \", np.array(y_test).shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training input data :  (40765, 75)\n",
            "Size of training output data :  (40765, 75, 18)\n",
            "Size of testing input data :  (7194, 75)\n",
            "Size of testing output data :  (7194, 75, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMjVCg8WSGHu",
        "colab_type": "code",
        "outputId": "3c1bb195-761e-4968-911a-353f6a407591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Let's check the first sentence before and after processing.\n",
        "print('*****Before Processing first sentence : *****\\n', ' '.join([w[0] for w in sentences[0]]))\n",
        "print('*****After Processing first sentence : *****\\n ', X[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****Before Processing first sentence : *****\n",
            " Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
            "*****After Processing first sentence : *****\n",
            "  [ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 11 17  3 18 19 20 21 22 23\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Qa-pZqSHuv",
        "colab_type": "code",
        "outputId": "d9969da1-ff08-44c7-f541-50aee79d2afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "# First label before and after processing.\n",
        "print('*****Before Processing first sentence : *****\\n', ' '.join([w[2] for w in sentences[0]]))\n",
        "print('*****After Processing first sentence : *****\\n ', y[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****Before Processing first sentence : *****\n",
            " O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
            "*****After Processing first sentence : *****\n",
            "  [[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbpbAOSCSK--",
        "colab_type": "text"
      },
      "source": [
        "## Bidirectional LSTM-CRF Network¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-MHt3RBSJVq",
        "colab_type": "code",
        "outputId": "7896977b-84bd-4f7c-904e-f0c113007b8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "num_tags = df['Tag'].nunique()\n",
        "# Model architecture\n",
        "input = Input(shape = (max_len,))\n",
        "model = Embedding(input_dim = len(words) + 2, output_dim = embedding, input_length = max_len)(input)\n",
        "model = Bidirectional(LSTM(units = 50, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)\n",
        "crf = CRF(num_tags+1)  # CRF layer\n",
        "out = crf(model)  # output\n",
        "\n",
        "model = Model(input, out)\n",
        "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 75)                0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 75, 40)            1407200   \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 75, 100)           36400     \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 75, 50)            5050      \n",
            "_________________________________________________________________\n",
            "crf_5 (CRF)                  (None, 75, 18)            1278      \n",
            "=================================================================\n",
            "Total params: 1,449,928\n",
            "Trainable params: 1,449,928\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs4p99wgSM6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath = 'model.h5',\n",
        "                       verbose = 0,\n",
        "                       mode = 'auto',\n",
        "                       save_best_only = True,\n",
        "                       monitor='val_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpfV6GpYSONb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "08ed88ce-ca23-4e4f-d8a9-b1263a581d0e"
      },
      "source": [
        "history = model.fit(X_train, np.array(y_train), batch_size=batch_size, epochs=epochs,\n",
        "                    validation_split=0.1, callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 36688 samples, validate on 4077 samples\n",
            "Epoch 1/8\n",
            "12032/36688 [========>.....................] - ETA: 1:15 - loss: 0.3409 - crf_viterbi_accuracy: 0.9195"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMywn7NKUZBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history.keys()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNA609aKUZXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['crf_viterbi_accuracy']\n",
        "val_acc = history.history['val_crf_viterbi_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.figure(figsize = (8, 8))\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1M5rtsQUb2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (8, 8))\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4B8SuPdUgWw",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the model on test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kplt-Q96Udmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_test_true = np.argmax(y_test, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoJ0oHV9UiYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the index to tag\n",
        "y_pred = [[idx2tag[i] for i in row] for row in y_pred]\n",
        "y_test_true = [[idx2tag[i] for i in row] for row in y_test_true]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j29bH9ImUju4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"F1-score is : {:.1%}\".format(f1_score(y_test_true, y_pred)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvUJ5c-JUll3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = flat_classification_report(y_pred=y_pred, y_true=y_test_true)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWFhusozUnaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# At every execution model picks some random test sample from test set.\n",
        "i = np.random.randint(0,X_test.shape[0]) # choose a random number between 0 and len(X_te)b\n",
        "p = model.predict(np.array([X_test[i]]))\n",
        "p = np.argmax(p, axis=-1)\n",
        "true = np.argmax(y_test[i], -1)\n",
        "\n",
        "print(\"Sample number {} of {} (Test Set)\".format(i, X_test.shape[0]))\n",
        "# Visualization\n",
        "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
        "print(30 * \"=\")\n",
        "for w, t, pred in zip(X_test[i], true, p[0]):\n",
        "    if w != 0:\n",
        "        print(\"{:15}: {:5} {}\".format(words[w-2], idx2tag[t], idx2tag[pred]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNyXbGW0UpsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}