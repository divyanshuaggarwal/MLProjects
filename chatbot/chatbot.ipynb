{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string # to process standard python strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/divyanshuaggarwal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/divyanshuaggarwal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "f=open('chatbot.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase\n",
    "nltk.download('punkt') # first-time use only\n",
    "nltk.download('wordnet') # first-time use only\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chatbot', 'from']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]\n",
    "\n",
    "word_tokens[:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "def greeting(sentence):\n",
    " \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: hello\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " wassup?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: I am sorry! I don't understand you\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " background\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: [6]\n",
      "contents\n",
      "\t\t1\n",
      "\t\tbackground\n",
      "\t\t2\n",
      "\t\tdevelopment\n",
      "\t\t3\n",
      "\t\tapplication\n",
      "\t\t3.1\n",
      "\t\tmessaging apps\n",
      "\t\t3.1.1\n",
      "\t\tas part of company apps and websites\n",
      "\t\t3.2\n",
      "\t\tcompany internal platforms\n",
      "\t\t3.3\n",
      "\t\tbanking\n",
      "\t\t3.4\n",
      "\t\ttoys\n",
      "\t\t3.5\n",
      "\t\tchatbots in medicine and for mental health\n",
      "\t\t4\n",
      "\t\tchatbot development platforms\n",
      "\t\t5\n",
      "\t\tmalicious use\n",
      "\t\t6\n",
      "\t\texamples of malicious uses for chatbots\n",
      "\t\t7\n",
      "\t\tlimitations of chatbots\n",
      "\t\t8\n",
      "\t\tchatbots killing jobs\n",
      "\t\t9\n",
      "\t\tsee also\n",
      "\t\t10\n",
      "\t\tcitations\n",
      "\t\t11\n",
      "\t\treferencesbackground[edit]\n",
      "in 1950, alan turing's famous article \"computing machinery and intelligence\" was published,[7] which proposed what is now called the turing test as a criterion of intelligence.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " intelligent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: eliza showed that such an illusion is surprisingly easy to generate, because human judges are so ready to give the benefit of the doubt when conversational responses are capable of being interpreted as \"intelligent\".\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " why chatbot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: chatbot\n",
      "from wikipedia, the free encyclopedia\n",
      "\n",
      "\n",
      "jump to navigation\n",
      "jump to search\n",
      "for other uses, see chatbot (disambiguation).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " why\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: I am sorry! I don't understand you\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " when chatbot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: chatbot\n",
      "from wikipedia, the free encyclopedia\n",
      "\n",
      "\n",
      "jump to navigation\n",
      "jump to search\n",
      "for other uses, see chatbot (disambiguation).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " when was chatbot made\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: in 1984, a book called the policeman's beard is half constructed was published, allegedly written by the chatbot racter (though the program as released would not have been capable of doing so).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " first chatbot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: chatbot\n",
      "from wikipedia, the free encyclopedia\n",
      "\n",
      "\n",
      "jump to navigation\n",
      "jump to search\n",
      "for other uses, see chatbot (disambiguation).\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"ROBO: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"ROBO: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"ROBO: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBO: Bye! take care..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
